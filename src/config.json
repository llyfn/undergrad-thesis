{
  "model_name": "roberta-base",
  "dataset": "figlang-twitter",
  "output_dir": "./out",
  "batch_size": 64,
  "pretrain_epochs": 20,
  "epochs": 10,
  "pretrain_lr": 5e-5,
  "classifier_lr": 3e-5,
  "model_lr": 5e-7,
  "dropout": 0.1,
  "temperature": 0.2
}